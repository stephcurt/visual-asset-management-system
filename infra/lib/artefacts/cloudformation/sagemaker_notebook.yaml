AWSTemplateFormatVersion: 2010-09-09
Description: SageMaker Pipeline Setup
Parameters:
  EnablePipelineLambdaFunction:
    Description: Function to enable the pipeline
    Type: String
  EnablePipelineLambdaFunctionArn:
    Description: Arn for Function to enable the pipeline
    Type: String
  DatabaseId:
    Description: Database ID to create the pipeline for
    Type: String
  PipelineName:
    Description: Pipeline Name
    Type: String
  S3Bucket:
    Description: S3 Bucket name that contains template.
    Type: String
  SagemakerBucketName:
    Description: S3 Bucket name that contains template.
    Type: String
  SagemakerBucketArn:
    Description: Arn for s3 bucket used by sagemaker jobs.
    Type: String
  AssetBucketArn:
    Description: Arn for s3 bucket used by vams assets.
    Type: String     
  SageMakeNotebookInstanceType:
    Description: Instance type for SageMaker notebook instance
    Type: String
    Default: ml.t2.medium
    AllowedValues:
      - ml.t2.medium
      - ml.t3.medium
Resources:
  ECRepository:
    Metadata:
      checkov:
        skip:
          - id: "CKV_AWS_51"
            comment: "The image may be built multiple times by the pipeline creator and adding immutability will prevent that from happening"
    Type: 'AWS::ECR::Repository'
    Properties:
      ImageScanningConfiguration:
        ScanOnPush: True
      EncryptionConfiguration:
        EncryptionType: "KMS"
      RepositoryName: !Ref PipelineName
  NotebookIAMRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - sagemaker.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
  NotebookIAMRolePolicy:
    Type: 'AWS::IAM::ManagedPolicy'
    Metadata:
      cdk_nag:
        rules_to_suppress:
          - id: "AwsSolutions-IAM5"
            reason: "Pipelines will need access to the entire bucket because the asset chosen to run the pipeline is not known at build time"
    Properties:
      Roles:
        - !Ref NotebookIAMRole
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action: 
              - 's3:GetObject'
            Resource: 
              - !Join ['', ['arn:aws:s3:::', !Ref S3Bucket, '/*']]  
          - Effect: Allow
            Action:
              - 's3:GetObject'
              - 's3:PutObject'
              - 's3:ListBucket'
              - 's3:AbortMultipartUpload'
            Resource: 
              - !Join ['', [!Ref SagemakerBucketArn, '/*']]
              - !Join ['', [!Ref AssetBucketArn, '/*']]
          - Action: # Borrowed from: https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-push.html
              - 'ecr:BatchCheckLayerAvailability'
              - 'ecr:CompleteLayerUpload'
              - 'ecr:BatchDeleteImage'
              - 'ecr:UploadLayerPart'
              - 'ecr:InitiateLayerUpload'
              - 'ecr:PutImage'
            Resource: 
              - !GetAtt ECRepository.Arn
            Effect: Allow
          - Action: # Borrowed from: https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-push.html
              - 'ecr:GetAuthorizationToken'
            Resource:
              - '*'
            Effect: Allow
          - Effect: Allow
            Action:
              - 'sts:DecodeAuthorizationMessage'
              - 'sts:GetAccessKeyInfo'
              - 'sts:GetCallerIdentity'
            Resource: '*'           
          - Effect: Allow
            Action:
              - 'sagemaker:CreateProcessingJob'
              - 'sagemaker:CreateAutoMLJob'
              - 'sagemaker:DescribeProcessingJob'
            NotResource:
              - 'arn:aws:sagemaker:*:*:domain/*'
              - 'arn:aws:sagemaker:*:*:user-profile/*'
              - 'arn:aws:sagemaker:*:*:app/*'
              - 'arn:aws:sagemaker:*:*:flow-definition/*'
          - Action:
              - 'iam:PassRole'
              - 'iam:GetRole'
            Resource:
              - !Join ['', ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/*AmazonSageMaker*']]
            Effect: Allow
          - Action:
              - 'iam:PassRole'
              - 'iam:GetRole'
            Resource:
              - !Join ['', ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/*NotebookIAMRole*']]
            Effect: Allow
          - Action:
              - 'logs:CreateLogDelivery'
              - 'logs:CreateLogGroup'
              - 'logs:CreateLogStream'
              - 'logs:DeleteLogDelivery'
              - 'logs:Describe*'
              - 'logs:GetLogDelivery'
              - 'logs:GetLogEvents'
              - 'logs:ListLogDeliveries'
              - 'logs:PutLogEvents'
              - 'logs:PutResourcePolicy'
              - 'logs:UpdateLogDelivery'
            Resource:
              - !Join [':', ['arn:aws:logs', !Ref "AWS::Region",  !Ref "AWS::AccountId", 'log-group', '/aws/sagemaker/']]
            Effect: Allow
          - Action: 
              - 'lambda:InvokeFunction'
            Resource:
              - !Ref EnablePipelineLambdaFunctionArn
            Effect: Allow
  NotebookLifeCycleConfig:
    Type: 'AWS::SageMaker::NotebookInstanceLifecycleConfig'
    Properties:
      OnCreate:
        - Content: !Base64 
            'Fn::Sub': >
              #!/bin/bash

              set -e

              sudo -u ec2-user -i <<'EOF'

              export ECR_NAME=${ECRepository}

              export S3_NAME=${S3Bucket}

              export DB_ID=${DatabaseId}

              export LAMBDA_NAME=${EnablePipelineLambdaFunction}

              export PIPELINE_NAME=${PipelineName}

              # Installing jq to construct json strings

              sudo yum install jq

              # This will affect only the Jupyter kernel called "R".

              source activate R

              # Replace myPackage with the name of the package you want to
              install.

              # You can also perform "conda install" here as well.

              conda install -y r-essentials r-base r-rjdbc

              conda install -c bioconda bioconductor-all -y

              source deactivate               

              aws s3 cp s3://$S3_NAME/notebooks/sagemakerTemplate.ipynb SageMaker/pipelineTemplate.ipynb 

              echo "Enabling pipeline"

              PAYLOAD=$( jq -n -c --arg db "$DB_ID" --arg pp "$PIPELINE_NAME"
              '{"pipelineId": $pp, "databaseId": $db}' )

              echo "Payload is $PAYLOAD" 

              aws lambda invoke --function-name $LAMBDA_NAME --payload $PAYLOAD
              response.json

              EOF

              touch /etc/profile.d/jupyter-env.sh

              echo "export ECR_NAME=${ECRepository}" >>
              /etc/profile.d/jupyter-env.sh

              echo "export S3_NAME=${SagemakerBucketName}" >>
              /etc/profile.d/jupyter-env.sh

              # initctl restart jupyter-server --no-wait
      OnStart:
        - Content: !Base64 >
            #!/bin/bash

            set -e

            sudo -u ec2-user -i <<'EOF'


            #The code below stops a sagaemaker notebook once it exceeds 1 hour
            of idle time. 

            # PARAMETERS

            IDLE_TIME=3600


            echo "Fetching the autostop script"

            wget
            https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-notebook-instance-lifecycle-config-samples/master/scripts/auto-stop-idle/autostop.py


            echo "Starting the SageMaker autostop script in cron"

            (crontab -l 2>/dev/null; echo "*/5 * * * * /usr/bin/python
            $PWD/autostop.py --time $IDLE_TIME --ignore-connections") | crontab
            -


            EOF
  NotebookInstance:
    Metadata:
      cdk_nag:
        rules_to_suppress:
          - id: AwsSolutions-SM1
            reason: "Instance is only created to build the container and can be terminated once the container is created. Adding a VPC will require extra cleanup that is not needed for a short lived instance"
          - id: AwsSolutions-SM2
            reason: "Instance is only created to build the container and we don't expect to have any long lived data residing on this instance"
          - id: AwsSolutions-SM3
            reason: "Access is required to download packages and connect to the notebook instance"
    DependsOn:
      - NotebookIAMRole
      - NotebookIAMRolePolicy
      - NotebookLifeCycleConfig
    Type: 'AWS::SageMaker::NotebookInstance'
    Properties:
      InstanceType: !Ref SageMakeNotebookInstanceType
      DirectInternetAccess: Enabled
      PlatformIdentifier: notebook-al2-v1
      RoleArn: !GetAtt 
        - NotebookIAMRole
        - Arn
      LifecycleConfigName: !GetAtt 
        - NotebookLifeCycleConfig
        - NotebookInstanceLifecycleConfigName
      NotebookInstanceName: !Ref PipelineName
Outputs:
  SageMakerNotebookName:
    Description: SageMaker notebook instance name
    Value: !GetAtt 
      - NotebookInstance
      - NotebookInstanceName
  SageMakerNotebook:
    Description: SageMaker notebook instance
    Value: !Join 
      - ''
      - - 'https://console.aws.amazon.com/sagemaker/home?region='
        - !Ref 'AWS::Region'
        - '#/notebook-instances/'
        - !GetAtt 
          - NotebookInstance
          - NotebookInstanceName
  JupyterLab:
    Description: SageMaker notebook instance
    Value: !Join 
      - ''
      - - 'https://'
        - !GetAtt 
          - NotebookInstance
          - NotebookInstanceName
        - .notebook.
        - !Ref 'AWS::Region'
        - .sagemaker.aws/lab
