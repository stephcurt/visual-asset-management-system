{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabe36c0",
   "metadata": {},
   "source": [
    "# Template for creating a data processing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sagemaker import get_execution_role, local, utils, Session\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketName = os.getenv('S3_NAME')\n",
    "print(bucketName)\n",
    "session = Session()\n",
    "default_bucket = bucketName\n",
    "role = get_execution_role()\n",
    "region = session.boto_region_name\n",
    "client = session.boto_session.client(\n",
    "    \"sts\", region_name=region, endpoint_url=utils.sts_regional_endpoint(region)\n",
    "    )\n",
    "account = client.get_caller_identity()['Account']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9327d940",
   "metadata": {},
   "source": [
    "## Setup a project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = os.getenv('ECR_NAME')\n",
    "directory = f'containers/{algorithm}'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "ecr_script_name = 'publish-ecr.sh'\n",
    "ecr_script_path = f'{directory}/{ecr_script_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464805d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $ecr_script_path\n",
    "#!/usr/bin/env bash\n",
    "set -u\n",
    "# The name of the repository where we'll publish container images\n",
    "REPOSITORY_NAME=\"$1\"\n",
    "# The image tag (for example, for versioning)\n",
    "IMAGE_TAG=latest\n",
    "# The identifier of the account where we want to publish container images\n",
    "# This is pulled automatically from the same account where this notebook is running\n",
    "ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\n",
    "# The current region (defaults to eu-west-1, if none defined)\n",
    "REGION=$(aws configure get region)\n",
    "# Build the base repository URI\n",
    "ECR_BASE=\"${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com\"\n",
    "# Build the entire URI for the container image\n",
    "ECR_FULL=\"${ECR_BASE}/${REPOSITORY_NAME}:${IMAGE_TAG}\"\n",
    "# No command should fail from here onwards\n",
    "set -e\n",
    "# Log in to Amazon ECR\n",
    "# https://docs.aws.amazon.com/AmazonECR/latest/userguide/getting-started-cli.html\n",
    "aws ecr get-login-password --region ${REGION} | \\\n",
    "docker login \"${ECR_BASE}\" --username AWS --password-stdin 2>/dev/null\n",
    "# Build Docker image\n",
    "docker build -t ${REPOSITORY_NAME} -f $2 .\n",
    "docker tag ${REPOSITORY_NAME} \"${ECR_FULL}\"\n",
    "# Push!\n",
    "# NOTE: an IAM policy similar to one in `iam-policy.json` is required!\n",
    "docker push \"${ECR_FULL}\"\n",
    "# Log out\n",
    "docker logout \"${ECR_BASE}\"\n",
    "echo \"Image is available at ${ECR_FULL}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0860d64",
   "metadata": {},
   "source": [
    "## Create script file\n",
    "This is the script that we will be executing from our container. The script can be in any language provided that the docker image supports it. Amazon SageMaker will load all of the data into the `opt/ml/processing/input` directory. Upon completion, SageMaker will export the data from `/opt/ml/processing/output` to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25588cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_name = 'script'\n",
    "script_path = f'{directory}/{script_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_path\n",
    "\n",
    "import numpy\n",
    "import math\n",
    "import csv\n",
    "import pathlib\n",
    "import os\n",
    "from stl import mesh\n",
    "\n",
    "INPUT_DIR =  '/opt/ml/processing/input'\n",
    "OUTPUT_DIR = '/opt/ml/processing/output'\n",
    "\n",
    "def main():\n",
    "    input_dir = pathlib.Path(INPUT_DIR)\n",
    "    file_name = os.listdir(input_dir)[-1]\n",
    "    print(os.listdir(input_dir))\n",
    "    print(f'Reading file {input_dir / file_name}', flush=True)\n",
    "\n",
    "    your_mesh = mesh.Mesh.from_file(input_dir / file_name)\n",
    "    output_dir = pathlib.Path(OUTPUT_DIR)\n",
    "    output_file = file_name.replace('.stl',f'_converted_from_stl.csv')\n",
    "    with open(output_dir / output_file,'w') as f1:\n",
    "        writer=csv.writer(f1, delimiter=',',lineterminator='\\n',)\n",
    "        writer.writerow(['x','y','z'])\n",
    "        for i in your_mesh.points:\n",
    "            for j in range(0, len(i), 3):\n",
    "                row = [i[j],i[j+1],i[j+2]]\n",
    "                writer.writerow(row)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58347248",
   "metadata": {},
   "source": [
    "## Create dockerfile\n",
    "This dockerfile will create the execution environment for our script. The script should be placed in the `/opt/ml/code/` directory and the `ENTRYPOINT` environment variable should have the proper command to execute the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf73596",
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerfile_name = 'Dockerfile'\n",
    "dockerfile_path = f'{directory}/{dockerfile_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dockerfile_path\n",
    "\n",
    "FROM python:3.8-slim-buster\n",
    "\n",
    "RUN pip3 uninstall -y stl\n",
    "RUN pip3 uninstall -y numpy-stl\n",
    "RUN pip3 install -U numpy-stl\n",
    "RUN pip3 uninstall -y pathlib\n",
    "RUN pip3 install -U pathlib\n",
    "\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "COPY script /opt/ml/code/script\n",
    "\n",
    "ENTRYPOINT [\"python3\", \"/opt/ml/code/script\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818233ff",
   "metadata": {},
   "source": [
    "## Build docker image and push it to ECR\n",
    "This script has three functions. It will create a repository if one doesn't already exist for our new docker image. It will then build the image using our dockerfile. Lastly, it will push our image into Amazon ECR so that we can utilize our code in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd242eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd $directory ; sh ./publish-ecr.sh $algorithm $dockerfile_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ae6f0",
   "metadata": {},
   "source": [
    "## Test run the container from SageMaker\n",
    "Through SageMaker, we can create a processing job to run our container. The instance type can be set to `local` to run on the notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eea4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'aws'\n",
    "preprocess_instance_type = 'ml.m5.large'\n",
    "image_uri = f'{account}.dkr.ecr.{region}-1.amazonaws.com/sagemaker-{algorithm}:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006fed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Processor(\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    instance_count=1,\n",
    "    instance_type=preprocess_instance_type,\n",
    "    base_job_name=project,\n",
    "    sagemaker_session=session,\n",
    "    volume_size_in_gb = 64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7fc47",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name='input',\n",
    "            source=f's3://{default_bucket}/{project}/{testfile}',\n",
    "            destination='/opt/ml/processing/input')\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='output',\n",
    "            source='/opt/ml/processing/output',\n",
    "            destination=f's3://{default_bucket}/{project}/output/{testfile}'\n",
    "        )\n",
    "    ],\n",
    "    arguments=[],\n",
    "    wait=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e618843ce4a002f2d89971d3f8063a9ef98e00c536c5d1f43fe67011a1546ec2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
